defaults:
  - logger: dummy
  - _self_

_target_: "pytorch_lightning.Trainer"
accelerator: "auto"
limit_train_batches: 1.0
max_epochs: 1
callbacks:
  - _target_: "src.callbacks.EarlyStoppingWithGrace"
    monitor: "${monitor}"
    patience: "${early_stopping.patience}"
    grace_epochs: "${early_stopping.grace_epochs}"
  - _target_: "pytorch_lightning.callbacks.ModelCheckpoint"
    dirpath: "checkpoints"
    every_n_epochs: null
    monitor: "${monitor}"
    save_top_k: 1
    mode: "min"
    save_last: true
    save_weights_only: false
  - _target_: "pytorch_lightning.callbacks.LearningRateMonitor"
    logging_interval: "step"
gradient_clip_algorithm: "value"
gradient_clip_val: 5